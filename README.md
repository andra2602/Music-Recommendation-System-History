# ğŸµ Reconstructing the History of Music Recommendation

### *Content-Based â€¢ Collaborative Filtering â€¢ Neural Item2Vec*

This project reconstructs the historical evolution of music recommendation systems by implementing three major paradigms: **Content-Based Filtering**, **Collaborative Filtering (SVD)**, and **Neural Item2Vec embeddings**.
Using the *Kaggle 30K Spotify Songs* dataset, we reproduce the core ideas that shaped modern recommendation engines and compare how each paradigm interprets musical similarity.

## Project Overview

Music recommendation systems evolved from **hand-crafted feature similarity**, to **statistical models based on collective behavior**, and finally to **neural contextual embeddings**.
Our goal was to rebuild these three eras from scratch, under a unified experimental framework.


### ğŸ“Š Dataset & Preprocessing

We use the **Kaggle 30,000 Spotify Songs** dataset (â‰ˆ30k tracks after cleaning).
Each track contains 10 normalized audio features (danceability, energy, valence, tempo, etc.) along with metadata such as artist and playlist genre.

Key preprocessing steps:

* removing duplicates & missing values
* normalizing audio features (Minâ€“Max)
* preparing interaction matrices & synthetic playlists

(see dataset overview in the *slides, page 5* )

# ğŸ”§ Models Implemented

### 1. Content-Based Filtering

Uses **cosine similarity** over normalized audio features to recommend songs with similar sound profiles.

**Highlights**

* requires no user history
* fast and fully interpretable
* PCA used for feature-space visualization

PCA clusters shown in *slides, page 6* .

### 2. Collaborative Filtering (SVD)

We simulate userâ€“song interactions to build a userâ€“item matrix, then apply **Matrix Factorization** (SVD) to learn latent taste factors.

**Highlights**

* predicts missing preferences
* captures behavioral similarity (co-listening patterns)
* stronger personalization than CBF

Example recommendation outputs shown on *slides, page 7* .

### 3. Neural Recommendation â€” Item2Vec

A Word2Vec-style model trained on playlists, treating each playlist as a â€œsentenceâ€ and each track as a â€œword.â€

We trained two variants:

1. **Mixed playlists** â€“ captures broad compatibility
2. **Genre-structured playlists** â€“ yields clearer embedding clusters

t-SNE visualization of learned embeddings is shown on *slides, page 8* .

# ğŸ§  Results & Insights

Across the three paradigms, similarity is defined differently:

| Paradigm                    | Similarity Basis | Strengths                          | Limitations                 |
| --------------------------- | ---------------- | ---------------------------------- | --------------------------- |
| **Content-Based**           | Audio features   | Interpretable, fast                | No personalization          |
| **Collaborative Filtering** | User behavior    | Personalized, learns hidden tastes | Needs real interaction data |
| **Item2Vec (Neural)**       | Playlist context | Captures vibe / mood               | Needs large real playlists  |

**Key insight:**

> Combining multiple paradigms yields a more robust recommender â€” each captures a unique facet of musical similarity.
> (See *Conclusion section in report* )

# Limitations

As described in both the PPT and report:

* no real user logs â†’ CF trained on simulated data
* playlists had to be **synthetically generated**
* audio features limited to 7 descriptors
* simplified models compared to industrial recommender systems
* evaluation restricted to internal consistency (PCA, cos-sim, t-SNE)

(see *Limitations, slides page 9*  and *report section 3* )


# ğŸ”® Future Work

From both team membersâ€™ reflections and project goals:

* design a **custom neural architecture** beyond Word2Vec
* build a **unified graphical interface** to explore recommendations interactively
* train on **realistic large-scale playlists** (e.g., Million Playlist Dataset)
* implement **hybrid recommendation systems**
* extend analysis to **multimodal signals** (lyrics, emotional embeddings)

(*slides page 11* and *report, section 4* )


# ğŸ‘¥ Contributions

### **Andra Mihaela AndruÈ›Äƒ**

* dataset preprocessing & cleaning
* exploratory data analysis
* CBF implementation
* PCA & word cloud analysis
* Word2Vec training + semantic playlist transitions

(*slides page 3* )

### **Ioana Alexandra Tunaru**

* playlist corpus generation
* CF (SVD) implementation
* top-N recommendations
* popularity vs personalization evaluation
* comparative study CBF vs CF

(*slides page 4* )


# ğŸ› ï¸ How to Run

All experiments were executed in **Google Colab**.

### Install dependencies:

```bash
pip install numpy pandas scikit-learn gensim scikit-surprise matplotlib seaborn
```

### Run notebook:
`KaggleProiectAMI.ipynb`

No GPU is required â€” all models train in seconds.


# Contact

For academic use or questions:

* **Andra Mihaela AndruÈ›Äƒ** â€“ [andra-mihaela.andruta@s.unibuc.ro](mailto:andra-mihaela.andruta@s.unibuc.ro)
* **Ioana Alexandra Tunaru** â€“ [ioana-alexandra.tunaru@s.unibuc.ro](mailto:ioana-alexandra.tunaru@s.unibuc.ro)
